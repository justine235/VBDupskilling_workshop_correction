{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "For this workshop, you need:\n",
        "\n",
        "* An Azure Machine Learning workspace. \n",
        "* The Azure Machine Learning Python SDK v2 installed. \n",
        "\n",
        "To install the SDK you can either,\n",
        "\n",
        "Create a compute instance, which already has installed the latest AzureML Python SDK and is pre-configured for ML workflows.\n",
        "\n",
        "Use the followings commands to install Azure ML Python SDK v2:\n",
        "\n",
        "```bash\n",
        "conda activate <virtual_env_name>\n",
        "pip install azure-ai-ml==1.0.0\n",
        "```\n",
        "\n",
        "If you're using a virtual env, make sure to install the sdk inside the virtual env.\n",
        "\n",
        "The virtual environment for sdkv2 on Azure Notebooks is called `azureml_py310_sdkv2`.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to ML Client"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To connect to a workspace, you need to provide a subscription, resource group and workspace name. These details are used in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace.\n",
        "\n",
        "In the following example, the default Azure authentication is used along with the default workspace configuration or from any `config.json` file you might have copied into the folders structure. If no `config.json` is found, then you need to manually introduce the subscription_id, resource_group and workspace when creating `MLClient`.\n",
        "\n",
        "```python\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = None\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    # Enter details of your AzureML workspace\n",
        "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
        "    resource_group = \"<RESOURCE_GROUP>\"\n",
        "    workspace = \"<AZUREML_WORKSPACE_NAME>\"\n",
        "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)\n",
        "```\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "# Add config.json file to the workspace\n",
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential, path=\"config.json\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /mnt/batch/tasks/shared/LS_root/mounts/clusters/jcharley4/code/Users/jcharley/config.json\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1672323698390
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create Managed Compute\n",
        "\n",
        "A compute is a designated compute resource where you run your job or host your endpoint. Azure Machine learning supports the following types of compute:\n",
        "\n",
        "- **Compute instance** - a fully configured and managed development environment in the cloud. You can use the instance as a training or inference compute for development and testing. It's similar to a virtual machine on the cloud.\n",
        "\n",
        "- **Compute cluster** - a managed-compute infrastructure that allows you to easily create a cluster of CPU or GPU compute nodes in the cloud.\n",
        "\n",
        "- **Inference cluster** - used to deploy trained machine learning models to Azure Kubernetes Service. You can create an Azure Kubernetes Service (AKS) cluster from your Azure ML workspace, or attach an existing AKS cluster.\n",
        "\n",
        "- **Attached compute** - You can attach your own compute resources to your workspace and use them for training and inference.\n",
        "\n",
        "You can create a compute using the Studio, the cli and the sdk.\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "my_cluster = AmlCompute(\n",
        "    name=\"cpu-cluster-CA\",\n",
        "    type=\"amlcompute\", \n",
        "    size=\"STANDARD_DS3_V2\", \n",
        "    min_instances=0, \n",
        "    max_instances=2,\n",
        "    location=\"westeurope\", \t\n",
        ")\n",
        "\n",
        "ml_client.compute.begin_create_or_update(my_cluster)\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "AmlCompute({'type': 'amlcompute', 'created_on': None, 'provisioning_state': 'Succeeded', 'provisioning_errors': None, 'name': 'cpu-cluster-CA', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/66914bb5-9cb2-4f6d-a84d-8ff900446b22/resourceGroups/Learning/providers/Microsoft.MachineLearningServices/workspaces/test_learn/computes/cpu-cluster-CA', 'base_path': './', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f208940e0e0>, 'resource_id': None, 'location': 'westeurope', 'size': 'STANDARD_DS3_V2', 'min_instances': 0, 'max_instances': 2, 'idle_time_before_scale_down': 120.0, 'identity': None, 'ssh_public_access_enabled': True, 'ssh_settings': None, 'network_settings': <azure.ai.ml.entities._compute.compute.NetworkSettings object at 0x7f208940e440>, 'tier': 'dedicated'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1672320947763
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Register File Data Asset\n",
        "\n",
        "**Datastore** - Azure Machine Learning Datastores securely keep the connection information to your data storage on Azure, so you don't have to code it in your scripts.\n",
        "\n",
        "An Azure Machine Learning datastore is a **reference** to an **existing** storage account on Azure. The benefits of creating and using a datastore are:\n",
        "* A common and easy-to-use API to interact with different storage type. \n",
        "* Easier to discover useful datastores when working as a team.\n",
        "* When using credential-based access (service principal/SAS/key), the connection information is secured so you don't have to code it in your scripts.\n",
        "\n",
        "Supported Data Resources: \n",
        "\n",
        "* Azure Storage blob container\n",
        "* Azure Storage file share\n",
        "* Azure Data Lake Gen 1\n",
        "* Azure Data Lake Gen 2\n",
        "* Azure SQL Database \n",
        "* Azure PostgreSQL Database\n",
        "* Azure MySQL Database\n",
        "\n",
        "It is not a requirement to use Azure Machine Learning datastores - you can use storage URIs directly assuming you have access to the underlying data.\n",
        "\n",
        "You can create a datastore using the Studio, the cli and the sdk.\n",
        "\n",
        "<hr>\n",
        "\n",
        "\n",
        "\n",
        "**Data asset** - Create data assets in your workspace to share with team members, version, and track data lineage.\n",
        "\n",
        "By creating a data asset, you create a reference to the data source location, along with a copy of its metadata. \n",
        "\n",
        "The benefits of creating data assets are:\n",
        "\n",
        "* You can **share and reuse data** with other members of the team such that they do not need to remember file locations.\n",
        "* You can **seamlessly access data** during model training (on any supported compute type) without worrying about connection strings or data paths.\n",
        "* You can **version** the data.\n",
        "\n",
        "<hr>\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_data = Data(\n",
        "    path=\"../data/Day1-exercice5-Taxi/taxi-data.csv\",\n",
        "    type=AssetTypes.URI_FILE, # URI_FOLDER\n",
        "    description=\"Taxi dataset\",\n",
        "    name=\"taxi-data\"\n",
        ")\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r\u001b[32mUploading taxi-data.csv\u001b[32m (< 1 MB): 0.00B [00:00, ?B/s]\r\u001b[32mUploading taxi-data.csv\u001b[32m (< 1 MB): 100%|██████████| 1.22M/1.22M [00:00<00:00, 9.69MB/s]\r\u001b[32mUploading taxi-data.csv\u001b[32m (< 1 MB): 100%|██████████| 1.22M/1.22M [00:00<00:00, 9.57MB/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "Data({'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'taxi-data', 'description': 'Taxi dataset', 'tags': {}, 'properties': {}, 'id': '/subscriptions/66914bb5-9cb2-4f6d-a84d-8ff900446b22/resourceGroups/Learning/providers/Microsoft.MachineLearningServices/workspaces/test_learn/data/taxi-data/versions/3', 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f2088220250>, 'serialize': <msrest.serialization.Serializer object at 0x7f208821bfa0>, 'version': '3', 'latest_version': None, 'path': 'azureml://subscriptions/66914bb5-9cb2-4f6d-a84d-8ff900446b22/resourcegroups/Learning/workspaces/test_learn/datastores/workspaceblobstore/paths/LocalUpload/2e56e9007690a9db90f90b8830ddcde4/taxi-data.csv', 'referenced_uris': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1672320987170
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GOOD TO KNOW : Create a tabular dataset/data asset - MLTable format"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cat ../data/Day1-exercice5-Taxi/MLTable"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "$schema: https://azuremlschemas.azureedge.net/latest/MLTable.schema.json \r\ntype: mltable\r\n\r\npaths:\r\n  - file: ./taxi-data.csv\r\ntransformations:\r\n  - read_delimited:\r\n      delimiter: ,\r\n      encoding: ascii\r\n      header: all_files_same_headers"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML table file\r\n",
        "import mltable\r\n",
        "\r\n",
        "tbl = mltable.load(uri=\"../data/Day1-exercice5-Taxi\")\r\n",
        "tbl.to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "MLTable yaml is invalid: None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/mltable/_mltable_helper.py:78\u001b[0m, in \u001b[0;36m_read_yaml\u001b[0;34m(uri)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     mltable_yaml_dict \u001b[38;5;241m=\u001b[39m \u001b[43myaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m yaml\u001b[38;5;241m.\u001b[39mYAMLError:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/__init__.py:125\u001b[0m, in \u001b[0;36msafe_load\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mParse the first YAML document in a stream\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03mand produce the corresponding Python object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mto be safe for untrusted input.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSafeLoader\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[0;34m(stream, Loader)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/constructor.py:49\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_single_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/composer.py:36\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n\u001b[0;32m---> 36\u001b[0m     document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Ensure that the stream contains no more documents.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/composer.py:55\u001b[0m, in \u001b[0;36mComposer.compose_document\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Compose the root node.\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Drop the DOCUMENT-END event.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/composer.py:82\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(SequenceStartEvent):\n\u001b[0;32m---> 82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_sequence_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/composer.py:111\u001b[0m, in \u001b[0;36mComposer.compose_sequence_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(SequenceEndEvent):\n\u001b[0;32m--> 111\u001b[0m     node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    112\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/composer.py:64\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompose_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, parent, index):\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAliasEvent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     65\u001b[0m         event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/parser.py:98\u001b[0m, in \u001b[0;36mParser.check_event\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate:\n\u001b[0;32m---> 98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/parser.py:451\u001b[0m, in \u001b[0;36mParser.parse_block_mapping_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_block_mapping_key)\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_block_node_or_indentless_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/parser.py:271\u001b[0m, in \u001b[0;36mParser.parse_block_node_or_indentless_sequence\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_block_node_or_indentless_sequence\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindentless_sequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/yaml/parser.py:369\u001b[0m, in \u001b[0;36mParser.parse_node\u001b[0;34m(self, block, indentless_sequence)\u001b[0m\n\u001b[1;32m    368\u001b[0m             token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeek_token()\n\u001b[0;32m--> 369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ParserError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile parsing a \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m node\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m node, start_mark,\n\u001b[1;32m    370\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected the node content, but found \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m token\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    371\u001b[0m                     token\u001b[38;5;241m.\u001b[39mstart_mark)\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m event\n",
            "\u001b[0;31mParserError\u001b[0m: while parsing a block node\nexpected the node content, but found ','\n  in \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/jcharley4/code/Users/jcharley/VBD_Day1/correction/../data/Day1-exercice5-Taxi/MLTable\", line 8, column 18",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ML table file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmltable\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tbl \u001b[38;5;241m=\u001b[39m \u001b[43mmltable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/Day1-exercice5-Taxi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m tbl\u001b[38;5;241m.\u001b[39mto_pandas_dataframe()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/mltable/mltable.py:436\u001b[0m, in \u001b[0;36mload\u001b[0;34m(uri, storage_options)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misabs(base_path):\n\u001b[1;32m    435\u001b[0m         local_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), base_path)\n\u001b[0;32m--> 436\u001b[0m     mltable_dict \u001b[38;5;241m=\u001b[39m \u001b[43m_read_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m     _validate(mltable_dict)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path_type \u001b[38;5;241m==\u001b[39m _PathType\u001b[38;5;241m.\u001b[39mcloud:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/mltable/_mltable_helper.py:80\u001b[0m, in \u001b[0;36m_read_yaml\u001b[0;34m(uri)\u001b[0m\n\u001b[1;32m     78\u001b[0m         mltable_yaml_dict \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(stream)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m yaml\u001b[38;5;241m.\u001b[39mYAMLError:\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLTable yaml is invalid: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mltable_yaml_dict))\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mltable_yaml_dict\n",
            "\u001b[0;31mValueError\u001b[0m: MLTable yaml is invalid: None"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672323868913
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "# my_path must point to folder containing MLTable artifact (MLTable file + data\r\n",
        "# Supported paths include:\r\n",
        "# local: './<path>'\r\n",
        "# blob:  'https://<account_name>.blob.core.windows.net/<container_name>/<path>'\r\n",
        "# ADLS gen2: 'abfss://<file_system>@<account_name>.dfs.core.windows.net/<path>/'\r\n",
        "# Datastore: 'azureml://datastores/<data_store_name>/paths/<path>'\r\n",
        "\r\n",
        "my_data = Data(\r\n",
        "    path=\"../data/Day1-exercice5-Taxi/taxi-data.csv\",\r\n",
        "    type=AssetTypes.MLTABLE,\r\n",
        "    description=\"Taxi tabular dataset\",\r\n",
        "    name=\"taxi-tabular-data\",\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.data.create_or_update(my_data)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "\u001b[31m\n\nError: \n\n1) One or more files or folders do not exist.\n\n\nDetails: \n\nNo such file or directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/jcharley4/code/Users/jcharley/VBD_Day1/data/Day1-exercice5-Taxi/taxi-data.csv/MLTable\n\nResolutions:\nDouble-check the directory paths you provided and enter the correct paths.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: https://code.visualstudio.com/docs/datascience/azure-machine-learning. To set up VS Code, visit https://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\n\u001b[39m",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/_utils/utils.py:280\u001b[0m, in \u001b[0;36mload_yaml\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:  \u001b[38;5;66;03m# FileNotFoundError introduced in Python 3\u001b[39;00m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/mnt/batch/tasks/shared/LS_root/mounts/clusters/jcharley4/code/Users/jcharley/VBD_Day1/data/Day1-exercice5-Taxi/taxi-data.csv/MLTable'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/operations/_data_operations.py:179\u001b[0m, in \u001b[0;36mDataOperations.create_or_update\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    177\u001b[0m version \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mversion\n\u001b[0;32m--> 179\u001b[0m referenced_uris \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m referenced_uris:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/operations/_data_operations.py:253\u001b[0m, in \u001b[0;36mDataOperations._validate\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     metadata_contents \u001b[38;5;241m=\u001b[39m \u001b[43mread_local_mltable_metadata_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     metadata_yaml_path \u001b[38;5;241m=\u001b[39m Path(asset_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLTable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/_utils/_data_utils.py:36\u001b[0m, in \u001b[0;36mread_local_mltable_metadata_contents\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     35\u001b[0m metadata_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(Path(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLTable\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/_utils/utils.py:283\u001b[0m, in \u001b[0;36mload_yaml\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m    282\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValidationException(\n\u001b[1;32m    284\u001b[0m             message\u001b[38;5;241m=\u001b[39mmsg\u001b[38;5;241m.\u001b[39mformat(source),\n\u001b[1;32m    285\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39mmsg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[file_path]\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    286\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    287\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mGENERAL,\n\u001b[1;32m    288\u001b[0m             error_type\u001b[38;5;241m=\u001b[39mValidationErrorType\u001b[38;5;241m.\u001b[39mFILE_OR_FOLDER_NOT_FOUND,\n\u001b[1;32m    289\u001b[0m         )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# input should now be an readable file or stream. Parse it.\u001b[39;00m\n",
            "\u001b[0;31mValidationException\u001b[0m: No such file or directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/jcharley4/code/Users/jcharley/VBD_Day1/data/Day1-exercice5-Taxi/taxi-data.csv/MLTable",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# my_path must point to folder containing MLTable artifact (MLTable file + data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Supported paths include:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# local: './<path>'\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# blob:  'https://<account_name>.blob.core.windows.net/<container_name>/<path>'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ADLS gen2: 'abfss://<file_system>@<account_name>.dfs.core.windows.net/<path>/'\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Datastore: 'azureml://datastores/<data_store_name>/paths/<path>'\u001b[39;00m\n\u001b[1;32m     11\u001b[0m my_data \u001b[38;5;241m=\u001b[39m Data(\n\u001b[1;32m     12\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/Day1-exercice5-Taxi/taxi-data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mAssetTypes\u001b[38;5;241m.\u001b[39mMLTABLE,\n\u001b[1;32m     14\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaxi tabular dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtaxi-tabular-data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_data\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/operations/_data_operations.py:208\u001b[0m, in \u001b[0;36mDataOperations.create_or_update\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ex, (ValidationException, SchemaValidationError)):\n\u001b[0;32m--> 208\u001b[0m         \u001b[43mlog_and_raise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ex, HttpResponseError):\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;66;03m# service side raises an exception if we attempt to update an existing asset's asset path\u001b[39;00m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ex) \u001b[38;5;241m==\u001b[39m ASSET_PATH_ERROR:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/ai/ml/_exception_helper.py:277\u001b[0m, in \u001b[0;36mlog_and_raise_error\u001b[0;34m(error, debug, yaml_operation)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(formatted_error)\n",
            "\u001b[0;31mException\u001b[0m: \u001b[31m\n\nError: \n\n1) One or more files or folders do not exist.\n\n\nDetails: \n\nNo such file or directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/jcharley4/code/Users/jcharley/VBD_Day1/data/Day1-exercice5-Taxi/taxi-data.csv/MLTable\n\nResolutions:\nDouble-check the directory paths you provided and enter the correct paths.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: https://code.visualstudio.com/docs/datascience/azure-machine-learning. To set up VS Code, visit https://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\n\u001b[39m"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1672323704237
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Register Train Environment\r\n",
        "\r\n",
        "Azure Machine Learning environments define the execution environments for your **jobs** or **deployments** and encapsulate the dependencies for your code. \r\n",
        "\r\n",
        "Azure ML uses the environment specification to create the Docker container that your **training** or **scoring code** runs in on the specified compute target.\r\n",
        "\r\n",
        "Create an environment from a\r\n",
        "* conda specification\r\n",
        "* Docker image\r\n",
        "* Docker build context\r\n",
        "\r\n",
        "There are two types of environments in Azure ML: **curated** and **custom environments**. Curated environments are predefined environments containing popular ML frameworks and tooling. Custom environments are user-defined.\r\n",
        "\r\n",
        "<hr>\r\n",
        "\r\n",
        "We can register an **environment** with cli v2 or sdk v2 using the following syntax:\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\r\n",
        "\r\n",
        "my_environment = Environment(\r\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\r\n",
        "    conda_file=\"../../data-science/environment/train-conda.yml\",\r\n",
        "    name=\"taxi-train-env\",\r\n",
        "    description=\"Environment created from a Docker image plus Conda environment to train taxi model.\",\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.environments.create_or_update(my_environment)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}