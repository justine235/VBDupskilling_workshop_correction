{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import uuid\r\n",
        "from azure.ai.ml import command\r\n",
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml import Input\r\n",
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes\r\n",
        "from azure.ai.ml import MLClient\r\n",
        "from azure.identity import DefaultAzureCredential\r\n",
        "from azure.ai.ml.entities import (\r\n",
        "    ManagedOnlineEndpoint,\r\n",
        "    ManagedOnlineDeployment,\r\n",
        "    Model,\r\n",
        "    CodeConfiguration,\r\n",
        "    Environment,\r\n",
        ")\r\n",
        "\r\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /mnt/batch/tasks/shared/LS_root/mounts/clusters/jcharley4/code/Users/jcharley/config.json\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1674554696312
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 1 : CREATE ONLINE (REAL-TIME) ENDPOINT"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Online endpoints are endpoints that are used for online (real-time) inferencing. They receive data from clients and can send responses back in real time.\r\n",
        "\r\n",
        "An endpoint is an HTTPS endpoint that clients can call to receive the inferencing (scoring) output of a trained model. It provides:\r\n",
        "\r\n",
        "Authentication using \"key & token\" based auth\r\n",
        "SSL termination\r\n",
        "A stable scoring URI (endpoint-name.region.inference.ml.azure.com)\r\n",
        "A deployment is a set of resources required for hosting the model that does the actual inferencing. A single endpoint can contain multiple deployments.\r\n",
        "\r\n",
        "Features of the managed online endpoint:\r\n",
        "\r\n",
        "Test and deploy locally for faster debugging\r\n",
        "Traffic to one deployment can also be mirrored (copied) to another deployment.\r\n",
        "Application Insights integration\r\n",
        "Security\r\n",
        "Authentication: Key and Azure ML Tokens\r\n",
        "Automatic Autoscaling\r\n",
        "Visual Studio Code debugging\r\n",
        "blue-green deployment: An approach where a new version of a web service is introduced to production by deploying it to a small subset of users/requests before deploying it fully."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a unique name for the endpoint\r\n",
        "online_endpoint_name = \"taxi-online-\" + str(uuid.uuid4())[:8]\r\n",
        "print(online_endpoint_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "credit-endpoint-a60eb442\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674554778608
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an online endpoint\r\n",
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\r\n",
        "\r\n",
        "online_endpoint = ManagedOnlineEndpoint(\r\n",
        "    name=online_endpoint_name, \r\n",
        "    description=\"Taxi online endpoint\",\r\n",
        "    auth_mode=\"aml_token\",\r\n",
        ")\r\n",
        "ml_client.online_endpoints.begin_create_or_update(\r\n",
        "    online_endpoint,   \r\n",
        ")\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://credit-endpoint-a60eb442.westeurope.inference.ml.azure.com/score', 'swagger_uri': 'https://credit-endpoint-a60eb442.westeurope.inference.ml.azure.com/swagger.json', 'name': 'credit-endpoint-a60eb442', 'description': 'Taxi online endpoint', 'tags': {}, 'properties': {'azureml.onlineendpointid': '/subscriptions/66914bb5-9cb2-4f6d-a84d-8ff900446b22/resourcegroups/learning/providers/microsoft.machinelearningservices/workspaces/test_learn/onlineendpoints/credit-endpoint-a60eb442', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/66914bb5-9cb2-4f6d-a84d-8ff900446b22/providers/Microsoft.MachineLearningServices/locations/westeurope/mfeOperationsStatus/oe:75310cf9-c772-4f21-9638-4129bab98f70:7beb4ba4-9ede-4046-a337-dca70797bc5f?api-version=2022-02-01-preview'}, 'id': '/subscriptions/66914bb5-9cb2-4f6d-a84d-8ff900446b22/resourceGroups/Learning/providers/Microsoft.MachineLearningServices/workspaces/test_learn/onlineEndpoints/credit-endpoint-a60eb442', 'base_path': './', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f2a2b7a6590>, 'auth_mode': 'aml_token', 'location': 'westeurope', 'identity': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedServiceIdentity object at 0x7f2a2b7a6350>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674555051282
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 2 : CREATE DEPLOYMENT TO (REAL-TIME) ENDPOINT"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\r\n",
        "\r\n",
        "To create a deployment to online endpoint, you need to specify the following elements:\r\n",
        "\r\n",
        "Model files (or specify a registered model in your workspace)\r\n",
        "Scoring script - code needed to do scoring/inferencing\r\n",
        "Environment - a Docker image with Conda dependencies, or a dockerfile\r\n",
        "Compute instance & scale settings\r\n",
        "Note that if you're deploying MLFlow models, there's no need to provide a scoring script and execution environment, as both are autogenerated.\r\n",
        "\r\n",
        "We can create an online deployment with cli v2 or sdk v2 using the following syntax:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's pick the latest version of the model\r\n",
        "\r\n",
        "# first option\r\n",
        "latest_model_version = max(\r\n",
        "    [int(m.version) for m in ml_client.models.list(name=\"taxi-model\")]\r\n",
        ")\r\n",
        "print(latest_model_version) \r\n",
        "\r\n",
        "# OR second option \r\n",
        "model = \"taxi-model@latest\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674555126141
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create online deployment\r\n",
        "from azure.ai.ml.entities import ManagedOnlineDeployment, Model, Environment\r\n",
        "\r\n",
        "blue_deployment = ManagedOnlineDeployment(\r\n",
        "    name=\"blue\",\r\n",
        "    endpoint_name=online_endpoint_name,\r\n",
        "    model=model,\r\n",
        "    instance_type=\"Standard_DS2_v2\",\r\n",
        "    instance_count=1,\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.online_deployments.begin_create_or_update(\r\n",
        "    deployment=blue_deployment\r\n",
        ")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint credit-endpoint-a60eb442 exists\nCreating/updating online deployment blue Done (9m 50s)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "..........................................................................................................."
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674555735365
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 3 : CONSUME THE MODEL"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\r\n",
        "import json\r\n",
        "import os\r\n",
        "import ssl\r\n",
        "\r\n",
        "def allowSelfSignedHttps(allowed):\r\n",
        "    # bypass the server certificate verification on client side\r\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\r\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\r\n",
        "\r\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\r\n",
        "\r\n",
        "# Request data goes here\r\n",
        "# The example below assumes JSON formatting which may be updated\r\n",
        "# depending on the format your endpoint expects.\r\n",
        "# More information can be found here:\r\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\r\n",
        "data =  {\"input_data\": \r\n",
        "      [\r\n",
        "    [2.86,40.66551971,-73.98258972,1,40.69801331,-73.97357178,0,2,1,1,19,21,3,56,1,1,19,21,21,57],\r\n",
        "    [3.98,40.68072128,-73.931633,1,40.6909523,-73.99185181,0,2,0,1,4,21,44,11,0,1,4,21,59,35]]\r\n",
        "}\r\n",
        "\r\n",
        "body = str.encode(json.dumps(data))\r\n",
        "\r\n",
        "url = 'https://credit-endpoint-a60eb442.westeurope.inference.ml.azure.com/score'\r\n",
        "# Replace this with the primary/secondary key or AMLToken for the endpoint\r\n",
        "api_key = ''\r\n",
        "if not api_key:\r\n",
        "    raise Exception(\"A key should be provided to invoke the endpoint\")\r\n",
        "\r\n",
        "# The azureml-model-deployment header will force the request to go to a specific deployment.\r\n",
        "# Remove this header to have the request observe the endpoint traffic rules\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'blue' }\r\n",
        "\r\n",
        "req = urllib.request.Request(url, body, headers)\r\n",
        "\r\n",
        "try:\r\n",
        "    response = urllib.request.urlopen(req)\r\n",
        "\r\n",
        "    result = response.read()\r\n",
        "    print(result)\r\n",
        "except urllib.error.HTTPError as error:\r\n",
        "    print(\"The request failed with status code: \" + str(error.code))\r\n",
        "\r\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\r\n",
        "    print(error.info())\r\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "b'[12.015454016944316, 14.8676752120793]'\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674556174460
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#second option to consume by sdk\r\n",
        "\r\n",
        "ml_client.online_endpoints.invoke(\r\n",
        "    endpoint_name=\"taxi-online-endpoint-2\",\r\n",
        "    request_file=\"../../data/taxi-request.json\",\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK V2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}